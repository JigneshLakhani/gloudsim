#summary Quick Start Steps.
#labels quickstart

= Quick Start =

  # Download the package using svn. 
  # Prerequisites: 
  * You need to install BLCR (Berkey Lab Checkpoint/Restart Toolkit). BLCR is used to perform checkpoint and restart for any running/failed program. If you encounter any problems, you can post the questions in BLCR discussion group, and the developers will reply you very soon with very great patience!
  * Install and set NFS (Network File System), e.g., called /cloudNFS
  * Install XEN3 or XEN4 on each physical machine, and make sure the XEN commands like “xm create xxx.cfg” are normal.
  * On each physical machine, you should bootup the VM instances before hand. In my testbed, for example, there are 8 physical machines, on each deploying 7 VM instances. Each physical machine has 8 cores, so it is necessary to reserve one core for XEN, which means there are only 7 cores to use if you hope to let each VM instance correspond to one core. At the end of this step, vm1,vm2,….,vm56 will be started on the 8 machines.
  * The VM version I used in my testbed is centos 5.3. You should configure the network (i.e., /etc/sysconfig/network-scripts/[NIC-card-config-file]) among the VM instances such that: (1) they can communicate each other; (2) they can communicate with physical machines (because physical machines are NFS servers). On VM instances, mount necessary directories, e.g., the VM image directory, the shared-disk (NFS) for storing checkpoint files, the local directory for storing checkpoint files. 
   *HINT*: You need to install BLCR on VM images. In fact, for simplicity, you could use NFS devise to install BLCR, and mount it onto any VM instance, then, every VM instance has BLCR installed.

  # 3.	You can use the java programs under fr.imag.mescal.gloudsim.prepare to prepare the necessary files used for simulation.

  * You need sample job files: For simplicity, I already generated the files for you. You could find them in the simFailureTrace directory.  In this directory, jobArrivalTrace.txt records the submission dates of jobs in the Google trace. There are three further sub-directories, single, batch, mix. They just contain corresponding types of jobs. For example, single means in the job, there is only one batchtask. In batch directory, each job has multiple parallel batchtasks (like mapreduce). “mix” means the mixture of the two types of jobs. 
(BatchTask actually refers to one TASK mentioned in the paper. A batchtask contains a chain of subtasks, each of which refers to an uninterrupted execution duration.)

  * You need to modify prop.config file for your environment. For example, how many physical machines to use.

  # Start the simulation using JobEmulator.java class, which is the entry point.
  # Some useful scripts can be found in the package.